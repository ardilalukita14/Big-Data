{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TUGAS-MINGGU-14.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNAMA87vnhJ166AgsmQ9Eg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ardilalukita14/Big-Data/blob/main/TUGAS_MINGGU_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BIG DATA - 14**\n",
        "\n",
        "## **ANALISA DAN VISUALISASI DATA** "
      ],
      "metadata": {
        "id": "ixVY9seV6NDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pengaturan PySpark di Colab**\n",
        "\n",
        "Spark ditulis menggunakan bahasa pemrogrraman Scala dan membutuhkan Java Virtual\n",
        "Machine (JVM) untuk menjalankannya. Sebagai langkah pertama, lakukan instalasi Java\n",
        "dengan menuliskan perintah di bawah ini."
      ],
      "metadata": {
        "id": "jMLzAJ2A6M9A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xHz9TFXx6Kdc"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk instalasi Apache Spark, unduh berkas menggunakan perintah wget kemudian\n",
        "ekstrak dengan perintah tar. Silahkan salin perintah berikut untuk melakukan instalasi."
      ],
      "metadata": {
        "id": "JlxLxfw-6Tpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "_6-2uvU-6VRi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebagai Langkah lanjutan, dibutuhkan pengaturan terkait Java dan Spark Home. Untuk\n",
        "melakukannya dapat memanfaatkan script pyton. Silahkan masukkan kode berikut ke\n",
        "dalam notebook."
      ],
      "metadata": {
        "id": "2DCfqg516aAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "018l2qbU6cNu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Konfigurasi PySpark**\n",
        "\n",
        "Konfigurasi PySpark dapat dilakukan dengan menginstall library findspark yang digunakan\n",
        "untuk mencari lokasi Spark yang terinstall pada sistem. Proses instalasi dapat\n",
        "memanfaatkan perintah pip, silahkan perhatikan perintah di bawah ini."
      ],
      "metadata": {
        "id": "wEReVTqg6dLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "u4BWEaIP6fCP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah proses instalasi berhasil, lakukan import library dan inisialisasi findspark. Silahkan\n",
        "salin kode berikut ke dalam notebook."
      ],
      "metadata": {
        "id": "WTtDE5lM6hYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "5LF3S1-u6i55"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Koneksi ke dalam spark dapat dilakukan memanfaatkan SparkSession. Salin kode berikut,\n",
        "dimana spark menggunakan port 4050."
      ],
      "metadata": {
        "id": "GAYC3jO86k6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        ".master(\"local\")\\\n",
        ".appName(\"Colab\")\\\n",
        ".config('spark.ui.port', '4050')\\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "K_kPCvZI6mmk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memasukkan data ke dalam PySpark**\n",
        "\n",
        "Spark mempunyai beberapa modul untuk membaca data dengan format yang berbeda.\n",
        "Spark secara otomatis akan menentukan tiap tipe data untuk setiap kolom. Data yang\n",
        "akan digunakan sebagai dataset dapat diunduh menggunakan perintah wget. Silahkan\n",
        "perhatikan perintah berikut."
      ],
      "metadata": {
        "id": "miSEk0_z6r3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --continue https://github.com/dhanifudin/pyspark-demo -O sample_books.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oge1b7aV6t47",
        "outputId": "ddd21973-3261-4c10-a406-124be0fcf2cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 02:31:12--  https://github.com/dhanifudin/pyspark-demo\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘sample_books.json’\n",
            "\n",
            "sample_books.json       [ <=>                ] 144.25K   781KB/s    in 0.2s    \n",
            "\n",
            "2022-05-31 02:31:13 (781 KB/s) - ‘sample_books.json’ saved [147707]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data yang telah diunduh dapat dibaca dengan menggunakan kode berikut. Silahkan salin\n",
        "kode berikut ke dalam notebook."
      ],
      "metadata": {
        "id": "F_TSggJV64Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json(\"sample_books.json\")"
      ],
      "metadata": {
        "id": "cI0UMrED60tg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analisa data menggunakan PySpark**\n",
        "\n",
        "Sebelum dapat menganalisa dataset, perlu mengetahui schema data yang akan diolah.\n",
        "Schema dapat diketahui dengan menggunakan kode berikut. Kode ini memanfaatkan\n",
        "dataframe."
      ],
      "metadata": {
        "id": "C2TIaD8S7DyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI-8n3gk7B91",
        "outputId": "1817418f-6c8f-4b5a-c6c2-0496511585e7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- author: string (nullable = true)\n",
            " |-- edition: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year_written: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menampilkan data**\n",
        "\n",
        "Dataset dapat ditampilkan dengan perintah show dari dataframe. Perintah show memiliki\n",
        "parameter berupa jumlah record yang ditampilkan serta opsi truncate. Silahkan salin kode\n",
        "beriikut ke dalam notebook."
      ],
      "metadata": {
        "id": "n2nuP1fk7It8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(4,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j5LfnvE7Rf9",
        "outputId": "5f8fe6a2-907d-40d0-d95f-9a2fc5eedf10"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+-----+----------------+------------+\n",
            "|author         |edition       |price|title           |year_written|\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "|Austen, Jane   |Penguin       |18.2 |Northanger Abbey|1814        |\n",
            "|Tolstoy, Leo   |Penguin       |12.7 |War and Peace   |1865        |\n",
            "|Tolstoy, Leo   |Penguin       |13.5 |Anna Karenina   |1875        |\n",
            "|Woolf, Virginia|Harcourt Brace|25.0 |Mrs. Dalloway   |1925        |\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menghitung jumlah dataset**\n",
        "\n",
        "Dataset dapat dihitung menggunakan fungsi count, silahkan salin kode berikut ke dalam\n",
        "untuk mengetahui jumlah dataset yang dimiliki."
      ],
      "metadata": {
        "id": "9ZW-FISK7ruv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-FiaCMr7sOg",
        "outputId": "efd13388-7684-4951-8a6f-6149bb375580"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Menampilkan kolom yang diinginkan**\n",
        "\n",
        "Dataset dapat dipilih untuk menampilkan data dengan kolom tertentu dengan fungsi\n",
        "select. Untuk menampilkan hanya kolom title, price dan year_written, silahkan salin kode\n",
        "berikut ke dalam colab."
      ],
      "metadata": {
        "id": "XQojkZBc7vFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"title\", \"price\", \"year_written\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRrtN487wse",
        "outputId": "b21da1e3-957d-4932-98e3-f119a89b5bc1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+------------+\n",
            "|           title|price|year_written|\n",
            "+----------------+-----+------------+\n",
            "|Northanger Abbey| 18.2|        1814|\n",
            "|   War and Peace| 12.7|        1865|\n",
            "|   Anna Karenina| 13.5|        1875|\n",
            "|   Mrs. Dalloway| 25.0|        1925|\n",
            "|       The Hours|12.35|        1999|\n",
            "+----------------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Me-filter dataset**\n",
        "\n",
        "PySpark dapat juga melakukan filter suatu dataset berdasarkan kondisi yang dibutuhkan.\n",
        "Sebagai contoh: dataset yang ingin ditampilkan adalah buku yang ditulis setelah tahun\n",
        "1950 dan harganya lebih dari $10. Filter dapat dilakukan dengan menuliskan kode berikut."
      ],
      "metadata": {
        "id": "TZ8OttLq72RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get books that are written after 1950 & cost greater than $10\n",
        "\n",
        "df_filtered = df.filter(\"year_written > 1950 AND price > 10 AND title IS NOT NULL\")\n",
        "df_filtered.select(\"title\", \"price\", \"year_written\").show(50, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1UuOjwa-HlG",
        "outputId": "eda3ae78-879c-46c0-c6e6-137033af51f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+-----+------------+\n",
            "|title                        |price|year_written|\n",
            "+-----------------------------+-----+------------+\n",
            "|The Hours                    |12.35|1999        |\n",
            "|Harry Potter                 |19.95|2000        |\n",
            "|One Hundred Years of Solitude|14.0 |1967        |\n",
            "+-----------------------------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penggunaan PySpark SQL functions**\n",
        "\n",
        "PySpark mempunyai fungsi SQL lainnya, misalnya max, aggregate function (groupBy, sum,\n",
        "count dll). Contoh: menampilkan data buku paling mahal, dapat menggunakan fungsi\n",
        "max."
      ],
      "metadata": {
        "id": "4u2dnALT8E0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "\n",
        "# Find the costliest book\n",
        "maxValue = df_filtered.agg(max(\"price\")).collect()[0][0]\n",
        "print(\"maxValue: \",maxValue)\n",
        "\n",
        "df_filtered.select(\"title\",\"price\").filter(df.price == maxValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvqWEbTy-Min",
        "outputId": "58f3f31c-1e06-40d1-fbcc-56219227d583"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxValue:  19.95\n",
            "+------------+-----+\n",
            "|title       |price|\n",
            "+------------+-----+\n",
            "|Harry Potter|19.95|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TUGAS**"
      ],
      "metadata": {
        "id": "OzkU5Dqy-Qqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tampilkan data buku dengan harga paling murah!"
      ],
      "metadata": {
        "id": "YztlwLa--TOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEzdkOoN_nPY",
        "outputId": "2169693e-a97f-4955-c9fe-ad1b2f037ac1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+-----+--------------------+------------+\n",
            "|              author|          edition|price|               title|year_written|\n",
            "+--------------------+-----------------+-----+--------------------+------------+\n",
            "|        Austen, Jane|          Penguin| 18.2|    Northanger Abbey|        1814|\n",
            "|        Tolstoy, Leo|          Penguin| 12.7|       War and Peace|        1865|\n",
            "|        Tolstoy, Leo|          Penguin| 13.5|       Anna Karenina|        1875|\n",
            "|     Woolf, Virginia|   Harcourt Brace| 25.0|       Mrs. Dalloway|        1925|\n",
            "|Cunnningham, Michael|   Harcourt Brace|12.35|           The Hours|        1999|\n",
            "|         Twain, Mark|          Penguin| 5.76|    Huckleberry Finn|        1865|\n",
            "|    Dickens, Charles|     Random House| 5.75|         Bleak House|        1870|\n",
            "|         Twain, Mark|     Random House| 7.75|          Tom Sawyer|        1862|\n",
            "|     Woolf, Virginia|          Penguin| 29.0| A Room of One's Own|        1922|\n",
            "|       Rowling, J.K.|   Harcourt Brace|19.95|        Harry Potter|        2000|\n",
            "|             Marquez|Harper  Perennial| 14.0|One Hundred Years...|        1967|\n",
            "|         Shakespeare| Signet  Classics| 7.95|Hamlet, Prince of...|        1603|\n",
            "|       Tolkien, J.R.|          Penguin|27.45|   Lord of the Rings|        1937|\n",
            "+--------------------+-----------------+-----+--------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min\n",
        "\n",
        "# Find the cheapest price\n",
        "\n",
        "minValue = df.agg(min(\"price\")).collect()[0][0]\n",
        "print(\"minValue: \",minValue)\n",
        "\n",
        "df.select(\"author\", \"edition\", \"price\", \"title\", \"year_written\").filter(df.price == minValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5RArZq4DIJB",
        "outputId": "f5f1de5d-ce3f-4d1a-f370-285f356d9b9e"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minValue:  5.75\n",
            "+----------------+------------+-----+-----------+------------+\n",
            "|author          |edition     |price|title      |year_written|\n",
            "+----------------+------------+-----+-----------+------------+\n",
            "|Dickens, Charles|Random House|5.75 |Bleak House|1870        |\n",
            "+----------------+------------+-----+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tampilkan jumlah terbit buku dikategorikan setiap tahun ditulis!"
      ],
      "metadata": {
        "id": "frDHcovYDJi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df.groupBy(\"year_written\").count().select(\"year_written\", f.col(\"count\").\n",
        "                                        alias(\"jumlah_terbit_buku_per_tahun\")).sort(desc(\"year_written\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIN3m3NWEACL",
        "outputId": "291c4c14-f247-424a-d29e-699c0f4c5c1e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------------------------+\n",
            "|year_written|jumlah_terbit_buku_per_tahun|\n",
            "+------------+----------------------------+\n",
            "|        2000|                           1|\n",
            "|        1999|                           1|\n",
            "|        1967|                           1|\n",
            "|        1937|                           1|\n",
            "|        1925|                           1|\n",
            "|        1922|                           1|\n",
            "|        1875|                           1|\n",
            "|        1870|                           1|\n",
            "|        1865|                           2|\n",
            "|        1862|                           1|\n",
            "|        1814|                           1|\n",
            "|        1603|                           1|\n",
            "+------------+----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tampilkan data buku termahal tiap tahun penulisannya!"
      ],
      "metadata": {
        "id": "1vlIKxLrE_v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df.groupBy(\"year_written\").agg({\"Price\" : \"max\"}).sort(desc(\"year_written\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSQ0dvgVFGpu",
        "outputId": "b1dadb82-224e-4bd8-b2ea-6b4657d5aeba"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|year_written|max(Price)|\n",
            "+------------+----------+\n",
            "|        2000|     19.95|\n",
            "|        1999|     12.35|\n",
            "|        1967|      14.0|\n",
            "|        1937|     27.45|\n",
            "|        1925|      25.0|\n",
            "|        1922|      29.0|\n",
            "|        1875|      13.5|\n",
            "|        1870|      5.75|\n",
            "|        1865|      12.7|\n",
            "|        1862|      7.75|\n",
            "|        1814|      18.2|\n",
            "|        1603|      7.95|\n",
            "+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tampilkan data buku termurah tiap tahun penulisannya!"
      ],
      "metadata": {
        "id": "JEhZD5jxFGz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df.groupBy(\"year_written\").agg({\"Price\" : \"min\"}).sort(desc(\"year_written\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niMvnXOGFIrJ",
        "outputId": "7f361757-5d01-4b6a-8193-6101eeec4730"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|year_written|min(Price)|\n",
            "+------------+----------+\n",
            "|        2000|     19.95|\n",
            "|        1999|     12.35|\n",
            "|        1967|      14.0|\n",
            "|        1937|     27.45|\n",
            "|        1925|      25.0|\n",
            "|        1922|      29.0|\n",
            "|        1875|      13.5|\n",
            "|        1870|      5.75|\n",
            "|        1865|      5.76|\n",
            "|        1862|      7.75|\n",
            "|        1814|      18.2|\n",
            "|        1603|      7.95|\n",
            "+------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}